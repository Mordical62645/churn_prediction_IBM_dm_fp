{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bb4f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# if using google colab, run this first: !gdown --fuzzy \"https://drive.google.com/file/d/1rYFumAaLcacQb59IYC-g_8douKWOIkTi/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c79935",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### LIBRARIES ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For splitting and scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For modeling and evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For handling imbalanced datasets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For high-performance models\n",
    "import xgboost as xgb\n",
    "\n",
    "# Optional: for building a simple interactive web app\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb23e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### DATASET ####\n",
    "# Load CSV\n",
    "file_path = \"IBM.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head()) # check column contents\n",
    "print(\"-\"*60,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e6f57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### DATA CLEANING ####\n",
    "# check for column datatypes\n",
    "print(df.info()) # TotalCharges' data type is string, which is weird. Blank strings might be the reason why it cannot be converted to float.\n",
    "print(\"-\"*60,\"\\n\")\n",
    "\n",
    "# work with missing values first because blank 'strings' cannot be converted to float\n",
    "print(df.isnull().sum()) # blank strings can be classified as not null.\n",
    "print(\"-\"*60,\"\\n\")\n",
    "\n",
    "# replace blank strings with NaN\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(\" \", np.nan)\n",
    "print(df.isnull().sum()) # recheck missing values.\n",
    "print(\"-\"*60,\"\\n\")\n",
    "\n",
    "# convert TotalCharges to float\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "print(df.info()) # recheck datatype\n",
    "print(\"-\"*60,\"\\n\")\n",
    "\n",
    "# Missing TotalCharges: 11 (less missing data are safe to drop, BRAD)\n",
    "df = df.dropna() # drop rows with missing (NaN) values: TotalCharges\n",
    "print(df.isnull().sum()) # check missing\n",
    "print(\"-\"*60,\"\\n\")\n",
    "\n",
    "# We'll temprorarily drop irrelevant columns for the model. This will reduce training load for the model to handle.\n",
    "# customerID is purely unique identifier. It's safe to drop.\n",
    "df = df.drop('customerID', axis = 1) # axis = 0: delete a row; axis = 1 delete a column\n",
    "\n",
    "# work with redundant data. I'll just use AI to check for that shit with 7000 rows motherfucker that's a lot to analyze.\n",
    "# According to my boy, BaiGPT. Mahimo natong i-standardize ang 'No phone service' ug 'No internet service' isip 'No' hinuon.\n",
    "# Let's just use \"No\" for 'No internet service' and 'No phone service'.\n",
    "df = df.replace({\n",
    "    'MultipleLines': {'No phone service':'No'},\n",
    "    'OnlineSecurity': {'No internet service':'No'},\n",
    "    'OnlineBackup': {'No internet service':'No'},\n",
    "    'DeviceProtection': {'No internet service':'No'},\n",
    "    'TechSupport': {'No internet service':'No'},\n",
    "    'StreamingTV': {'No internet service':'No'},\n",
    "    'StreamingMovies': {'No internet service':'No'},\n",
    "\n",
    "    # tinatamad na ako mag-ingles perd. May mga areas na okay naman like 'Bank transfer (automatic)' tsaka 'Credit card (automatic)'\n",
    "    # pwede naman na tanggaling yung '(automatic)' part.\n",
    "    # ganun din sa 'Contract' column. Yung casing lang like 'Month-To-Month' ganern!\n",
    "    'PaymentMethod': {\n",
    "        'Bank transfer (automatic)': 'Bank Transfer',\n",
    "        'Credit card (automatic)': 'Credit Card'\n",
    "    },\n",
    "    'Contract': {\n",
    "        'Month-to-month': 'Month-To-Month',\n",
    "        'One year': 'One Year',\n",
    "        'Two year': 'Two Year'\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e383beb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### HANDLE CLASS IMBALANCE + TRAIN TEST SPLIT ####\n",
    "# Map (not replace) numeric of 'Churn' instead of Yes or No, we'll do 1 or 0\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "df_encoded = pd.get_dummies(df) # Turn categorical data to numeric\n",
    "\n",
    "# Define the features (X) and labels (y).\n",
    "X = df_encoded.drop(columns=['Churn'])\n",
    "# print(X)\n",
    "y = df_encoded['Churn']\n",
    "# print(y)\n",
    "\n",
    "# Use train_test_split() to divide into training and test sets.\n",
    "  # X_train: Features for training\n",
    "  # X_test: Features for testing\n",
    "  # y_train: Labels for training\n",
    "  # y_test: Labels for testing\n",
    "  # test_size is how much data goes into test set (denoted by 0.2 = 20%)\n",
    "  # random_state is the seed so results is reproducible. No seed = random\n",
    "  # stratify=y ensures the class distribution in y is preserved in both the train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "  # 80% of data goes to training.\n",
    "  # 20% goes to testing.\n",
    "  # The proportion of churned vs. non-churned customers is the same in both sets.\n",
    "  # The split will always be the same every time you run it (because of random_state=42).\n",
    "\n",
    "# Apply SMOTE only to X_train and y_train.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print value_counts() to confirm class balance.\n",
    "print(f\"Before SMOTE:\\n {y_train.value_counts()}\")\n",
    "print(\"-\"*60,\"\\n\")\n",
    "print(f\"Afer SMOTE:\\n {y_train_resampled.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa7cdc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### FEATURE SCALING ####\n",
    "# Apply StandardScaler() or similar only to features (X), not labels (y).\n",
    "\n",
    "\n",
    "# Remember: fit on X_train, then transform both X_train and X_test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa44ffc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### MODELLING ####\n",
    "# LogisticRegression\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "\n",
    "\n",
    "# Fit the model using X_train and y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05787cb8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### EVALUATION ####\n",
    "# Predict on X_test.\n",
    "# Evaluate using:\n",
    "# Accuracy\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "\n",
    "# Classification report (precision, recall, F1-score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe589b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#### PREDICTION AND OUTPUT ####\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
